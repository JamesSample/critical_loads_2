{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib.util\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "from IPython.display import display\n",
    "from osgeo import gdal\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import CL functions\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"critical_loads\", \"../../notebooks/critical_loads.py\"\n",
    ")\n",
    "cl = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostGIS\n",
    "eng = nivapy.da.connect_postgis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Høyanger: Calculate exceedances\n",
    "\n",
    "**Note:** This notebook is rather messy and should be tidied up. In particular, cell 7 currently subsets the data to avoid issues with overlapping catchment polygons: the three non-overlapping polygons are processed simultaneously, and the fourth is then processed separately. This **requires running the notebook twice** (once for each catchment \"subset\"), each time changing the name of the summary CSV generated in section 5 to avoid overwriting. This is \"hacky\" and can be cleaned up, but it seems pragmatic for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get catchments of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Outflow points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_name</th>\n",
       "      <th>aquamonitor_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1285</td>\n",
       "      <td>EIR</td>\n",
       "      <td>Eiriksdal</td>\n",
       "      <td>None</td>\n",
       "      <td>6.215740</td>\n",
       "      <td>61.233612</td>\n",
       "      <td>POINT (29385.372 6820523.378)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1286</td>\n",
       "      <td>GAU</td>\n",
       "      <td>Gautingdalselva</td>\n",
       "      <td>None</td>\n",
       "      <td>6.144167</td>\n",
       "      <td>61.241150</td>\n",
       "      <td>POINT (25681.326 6821876.913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1287</td>\n",
       "      <td>HAA</td>\n",
       "      <td>Haaland</td>\n",
       "      <td>None</td>\n",
       "      <td>6.077150</td>\n",
       "      <td>61.220030</td>\n",
       "      <td>POINT (21785.963 6820029.835)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1288</td>\n",
       "      <td>HOY</td>\n",
       "      <td>Hoyanger</td>\n",
       "      <td>None</td>\n",
       "      <td>6.073730</td>\n",
       "      <td>61.216397</td>\n",
       "      <td>POINT (21548.133 6819652.935)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code     station_name aquamonitor_id  longitude  \\\n",
       "0        1285          EIR        Eiriksdal           None   6.215740   \n",
       "1        1286          GAU  Gautingdalselva           None   6.144167   \n",
       "2        1287          HAA          Haaland           None   6.077150   \n",
       "3        1288          HOY         Hoyanger           None   6.073730   \n",
       "\n",
       "    latitude                           geom  \n",
       "0  61.233612  POINT (29385.372 6820523.378)  \n",
       "1  61.241150  POINT (25681.326 6821876.913)  \n",
       "2  61.220030  POINT (21785.963 6820029.835)  \n",
       "3  61.216397  POINT (21548.133 6819652.935)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get outflows\n",
    "sql = (\n",
    "    \"SELECT * FROM niva.stations \"\n",
    "    \"WHERE station_id IN ( \"\n",
    "    \"  SELECT station_id FROM niva.projects_stations \"\n",
    "    \"  WHERE project_id IN ( \"\n",
    "    \"    SELECT project_id FROM niva.projects \"\n",
    "    \"    WHERE project_name = 'Høyanger' \"\n",
    "    \"    ) \"\n",
    "    \"  ) \"\n",
    ")\n",
    "stn_gdf = gpd.read_postgis(sql, eng)\n",
    "\n",
    "# Reproject to ETRS89 UTM Z33N\n",
    "stn_gdf = stn_gdf.to_crs(\"epsg:25833\")\n",
    "\n",
    "stn_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Catchment boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>geom</th>\n",
       "      <th>cat_area_km2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1285</td>\n",
       "      <td>EIR</td>\n",
       "      <td>MULTIPOLYGON (((37248.834 6823946.164, 37499.3...</td>\n",
       "      <td>71.965714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1286</td>\n",
       "      <td>GAU</td>\n",
       "      <td>MULTIPOLYGON (((29139.510 6824275.830, 29235.2...</td>\n",
       "      <td>5.869828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1287</td>\n",
       "      <td>HAA</td>\n",
       "      <td>MULTIPOLYGON (((22172.792 6822076.278, 22182.1...</td>\n",
       "      <td>3.608488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1288</td>\n",
       "      <td>HOY</td>\n",
       "      <td>MULTIPOLYGON (((29139.510 6824275.830, 29235.2...</td>\n",
       "      <td>96.946486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code                                               geom  \\\n",
       "0        1285          EIR  MULTIPOLYGON (((37248.834 6823946.164, 37499.3...   \n",
       "1        1286          GAU  MULTIPOLYGON (((29139.510 6824275.830, 29235.2...   \n",
       "2        1287          HAA  MULTIPOLYGON (((22172.792 6822076.278, 22182.1...   \n",
       "3        1288          HOY  MULTIPOLYGON (((29139.510 6824275.830, 29235.2...   \n",
       "\n",
       "   cat_area_km2  \n",
       "0     71.965714  \n",
       "1      5.869828  \n",
       "2      3.608488  \n",
       "3     96.946486  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get catchments\n",
    "stn_list = list(stn_gdf[\"station_id\"].astype(str))\n",
    "bind_pars = \",\".join(stn_list)\n",
    "sql = f\"SELECT * FROM niva.catchments \" f\"WHERE station_id IN ({bind_pars})\"\n",
    "cat_gdf = gpd.read_postgis(sql, eng)\n",
    "\n",
    "# Reproject to ETRS89 UTM Z33N\n",
    "cat_gdf = cat_gdf.to_crs(\"epsg:25833\")\n",
    "\n",
    "# Join codes\n",
    "cat_gdf = cat_gdf.merge(\n",
    "    stn_gdf[[\"station_id\", \"station_code\"]], how=\"left\", on=\"station_id\"\n",
    ")\n",
    "cat_gdf = cat_gdf[[\"station_id\", \"station_code\", \"geom\"]]\n",
    "\n",
    "# Add area\n",
    "cat_gdf[\"cat_area_km2\"] = cat_gdf[\"geom\"].area / 1e6\n",
    "\n",
    "cat_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate critical loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Process input template\n",
    "\n",
    "Kari has supplied two input templates - one for the \"main\" catchments and one for the subcatchments. This avoid issues of overlapping polygons during the rasterisation steps. **This notebook should therefore be run twice, modifying `catch_set` below, as necessary**.\n",
    "\n",
    "\n",
    "We wish to use the \"F-factor\" method for these calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose catchments to process (one of 'main', 'sub', 'sub_jan06')\n",
    "catch_set = \"main\"\n",
    "\n",
    "assert catch_set in [\"sub\", \"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to completed template\n",
    "xl_path = f\"../data/input_template_critical_loads_water_v1-1_hoyanger_{catch_set}.xlsx\"\n",
    "\n",
    "# Read template\n",
    "req_df = pd.read_excel(xl_path, sheet_name=\"required_parameters\")\n",
    "mag_df = pd.read_excel(xl_path, sheet_name=\"magic_parameters\")\n",
    "opt_df = pd.read_excel(xl_path, sheet_name=\"optional_parameters\")\n",
    "\n",
    "# Read quantites calculated in notebook 2 and patch input template\n",
    "# Required pars\n",
    "nupt_df = pd.read_csv(r\"../output/hoyanger_nupt_summary.csv\")\n",
    "nupt_df = pd.merge(nupt_df, stn_gdf, how=\"left\", on=\"station_id\")\n",
    "nupt_df = nupt_df[[\"station_name\", \"nupt_meqpm2pyr\"]]\n",
    "nupt_df.columns = [\"Region_id\", \"Nupt\"]\n",
    "del req_df[\"Nupt\"]\n",
    "req_df = pd.merge(req_df, nupt_df, how=\"left\", on=\"Region_id\")\n",
    "\n",
    "# Optional pars. See Section 3 here:\n",
    "# https://github.com/JamesSample/critical_loads_2/blob/master/notebooks/workflow_update_2023/02d_blr_summaries.ipynb\n",
    "lc_df = pd.read_csv(r\"../output/hoyanger_ar50_summary.csv\")\n",
    "class_dict = {\n",
    "    81: \"Lake_area\",\n",
    "    30: \"Forest_area\",\n",
    "    51: \"Bare_area\",\n",
    "    70: \"Bare_area\",\n",
    "    60: \"Peat_area\",\n",
    "    -1: \"Other_area\",\n",
    "}\n",
    "lc_df[\"lc_class\"] = np.where(lc_df[\"arveget\"] == 51, lc_df[\"arveget\"], lc_df[\"artype\"])\n",
    "lc_df[\"lc_class\"] = np.where(\n",
    "    lc_df[\"lc_class\"].isin(class_dict.keys()), lc_df[\"lc_class\"], -1\n",
    ")\n",
    "lc_df[\"lc_class\"].replace(class_dict, inplace=True)\n",
    "lc_df = lc_df.query(\n",
    "    \"lc_class in ('Lake_area', 'Forest_area', 'Bare_area', 'Peat_area')\"\n",
    ")\n",
    "lc_df = lc_df[[\"station_id\", \"lc_class\", \"area_km2\"]]\n",
    "lc_df = lc_df.groupby([\"station_id\", \"lc_class\"]).sum()\n",
    "lc_df = lc_df.unstack(\"lc_class\").fillna(0)\n",
    "lc_df.columns = lc_df.columns.get_level_values(1)\n",
    "lc_df.columns.name = \"\"\n",
    "lc_df.reset_index(inplace=True)\n",
    "\n",
    "lc_df = pd.merge(lc_df, stn_gdf, how=\"left\", on=\"station_id\")\n",
    "lc_df = pd.merge(\n",
    "    lc_df, cat_gdf[[\"station_id\", \"cat_area_km2\"]], how=\"left\", on=\"station_id\"\n",
    ")\n",
    "lc_df = lc_df[\n",
    "    [\n",
    "        \"station_name\",\n",
    "        \"cat_area_km2\",\n",
    "        \"Lake_area\",\n",
    "        \"Forest_area\",\n",
    "        \"Bare_area\",\n",
    "        \"Peat_area\",\n",
    "    ]\n",
    "]\n",
    "lc_df.columns = [\n",
    "    \"Region_id\",\n",
    "    \"Catch_area\",\n",
    "    \"Lake_area\",\n",
    "    \"Forest_area\",\n",
    "    \"Bare_area\",\n",
    "    \"Peat_area\",\n",
    "]\n",
    "opt_df.drop(\n",
    "    [\"Catch_area\", \"Lake_area\", \"Forest_area\", \"Bare_area\", \"Peat_area\"],\n",
    "    axis=\"columns\",\n",
    "    inplace=True,\n",
    ")\n",
    "opt_df = pd.merge(opt_df, lc_df, how=\"left\", on=\"Region_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in minimum\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in minimum\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region_id</th>\n",
       "      <th>CLAOAA_Ffac_meq/m2/yr</th>\n",
       "      <th>ENO3_flux_meq/m2/yr</th>\n",
       "      <th>CLminN_meq/m2/yr</th>\n",
       "      <th>CLmaxNoaa_Ffac_meq/m2/yr</th>\n",
       "      <th>CLmaxSoaa_Ffac_meq/m2/yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoyanger</td>\n",
       "      <td>61.182348</td>\n",
       "      <td>14.554914</td>\n",
       "      <td>1.632134</td>\n",
       "      <td>78.778131</td>\n",
       "      <td>62.231886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region_id  CLAOAA_Ffac_meq/m2/yr  ENO3_flux_meq/m2/yr  CLminN_meq/m2/yr  \\\n",
       "0  Hoyanger              61.182348            14.554914          1.632134   \n",
       "\n",
       "   CLmaxNoaa_Ffac_meq/m2/yr  CLmaxSoaa_Ffac_meq/m2/yr  \n",
       "0                 78.778131                 62.231886  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set BC0 method\n",
    "bc0_method = \"_Ffac\"\n",
    "\n",
    "# Calculate CLs\n",
    "cl_df = cl.calculate_critical_loads_for_water(\n",
    "    req_df=req_df, mag_df=mag_df, opt_df=opt_df\n",
    ")\n",
    "\n",
    "# Get cols of interest\n",
    "cols = [\n",
    "    \"Region_id\",\n",
    "    f\"CLAOAA{bc0_method}_meq/m2/yr\",\n",
    "    \"ENO3_flux_meq/m2/yr\",\n",
    "    \"CLminN_meq/m2/yr\",\n",
    "    f\"CLmaxNoaa{bc0_method}_meq/m2/yr\",\n",
    "    f\"CLmaxSoaa{bc0_method}_meq/m2/yr\",\n",
    "]\n",
    "cl_df = cl_df[cols]\n",
    "\n",
    "cl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Rasterise critical loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rasterising claoaa...\n",
      "Rasterising eno3...\n",
      "Rasterising clminn...\n",
      "Rasterising clmaxnoaa...\n",
      "Rasterising clmaxsoaa...\n",
      "Rasterising clmins...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_code</th>\n",
       "      <th>geom</th>\n",
       "      <th>cat_area_km2</th>\n",
       "      <th>claoaa</th>\n",
       "      <th>eno3</th>\n",
       "      <th>clminn</th>\n",
       "      <th>clmaxnoaa</th>\n",
       "      <th>clmaxsoaa</th>\n",
       "      <th>clmins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1288</td>\n",
       "      <td>HOY</td>\n",
       "      <td>MULTIPOLYGON (((29139.510 6824275.830, 29235.2...</td>\n",
       "      <td>96.946486</td>\n",
       "      <td>61.182348</td>\n",
       "      <td>14.554914</td>\n",
       "      <td>1.632134</td>\n",
       "      <td>78.778131</td>\n",
       "      <td>62.231886</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id station_code                                               geom  \\\n",
       "0        1288          HOY  MULTIPOLYGON (((29139.510 6824275.830, 29235.2...   \n",
       "\n",
       "   cat_area_km2     claoaa       eno3    clminn  clmaxnoaa  clmaxsoaa  clmins  \n",
       "0     96.946486  61.182348  14.554914  1.632134  78.778131  62.231886     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell size for rasterisation\n",
    "cell_size = 50\n",
    "\n",
    "# Snap tiff\n",
    "snap_tif = f\"../raster/hoyanger_snap_ras_{cell_size}m.tif\"\n",
    "\n",
    "# Simplify col names (as units are consistent)\n",
    "cl_df.columns = [i.split(\"_\")[0].lower() for i in cl_df.columns]\n",
    "cl_df.rename({\"region\": \"station_name\"}, inplace=True, axis=1)\n",
    "cl_df.dropna(how=\"any\", inplace=True)\n",
    "\n",
    "# Add CLminS as 0\n",
    "cl_df[\"clmins\"] = 0\n",
    "\n",
    "# Join to catchments\n",
    "cl_df = pd.merge(\n",
    "    cl_df, stn_gdf[[\"station_name\", \"station_code\"]], on=\"station_name\", how=\"left\"\n",
    ")\n",
    "del cl_df[\"station_name\"]\n",
    "cat_gdf = cat_gdf.merge(cl_df, how=\"left\", on=\"station_code\")\n",
    "cat_gdf.dropna(inplace=True)\n",
    "cat_gdf.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Save temporary file\n",
    "temp = \"../raster/temp.geojson\"\n",
    "cat_gdf.to_file(temp, driver=\"GeoJSON\")\n",
    "\n",
    "# Rasterize each column\n",
    "cols = [\"claoaa\", \"eno3\", \"clminn\", \"clmaxnoaa\", \"clmaxsoaa\", \"clmins\"]\n",
    "for col in cols:\n",
    "    print(f\"Rasterising {col}...\")\n",
    "    # Tiff to create\n",
    "    out_tif = f\"../raster/critical_loads/{col}_meqpm2pyr_{cell_size}m.tif\"\n",
    "    cl.vec_to_ras(temp, out_tif, snap_tif, col, -9999, \"Float32\")\n",
    "\n",
    "# Delete temp file\n",
    "os.remove(temp)\n",
    "\n",
    "cat_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process deposition data\n",
    "\n",
    "We will use the NILU historic series for 2012-16 (new method) to represent present-day conditions. For the future, we will use the EMEP scenarios for 2030 and 2050 provided for the GP review. A compatible EMEP run for 2015 (also provided for the GP review) will be used to calculate change factors that can be applied to the NILU series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Select NILU deposition series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>grid</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Middel 2012-2016 (new)</td>\n",
       "      <td>1216_blrgrid</td>\n",
       "      <td>blr</td>\n",
       "      <td>Fordelt til BLR av NILU 2017 (Wenche Aas; new method)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>Middel 2017-2021 (new)</td>\n",
       "      <td>1721_blrgrid</td>\n",
       "      <td>blr</td>\n",
       "      <td>Supplied by Met in 2023 (Lewis Blake; new method)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    series_id                    name    short_name grid  \\\n",
       "26  27         Middel 2012-2016 (new)  1216_blrgrid  blr   \n",
       "66  67         Middel 2017-2021 (new)  1721_blrgrid  blr   \n",
       "\n",
       "                                              description  \n",
       "26  Fordelt til BLR av NILU 2017 (Wenche Aas; new method)  \n",
       "66  Supplied by Met in 2023 (Lewis Blake; new method)      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List available series\n",
    "with pd.option_context(\"display.max_colwidth\", -1):\n",
    "    ser_grid = cl.view_dep_series(eng).query(\"series_id in [27, 67]\")\n",
    "    display(ser_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in series IDs 27 and 67."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Rasterise NILU deposition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rasterising nitrogen, 1216...\n",
      "WARNING: The specified series ID does NOT refer to the EMEP grid. The 'veg_class' parameter will be ignored.\n",
      "Rasterising nitrogen, 1721...\n",
      "WARNING: The specified series ID does NOT refer to the EMEP grid. The 'veg_class' parameter will be ignored.\n",
      "Rasterising sulphur, 1216...\n",
      "WARNING: The specified series ID does NOT refer to the EMEP grid. The 'veg_class' parameter will be ignored.\n",
      "Rasterising sulphur, 1721...\n",
      "WARNING: The specified series ID does NOT refer to the EMEP grid. The 'veg_class' parameter will be ignored.\n"
     ]
    }
   ],
   "source": [
    "# BLR grid, new method\n",
    "ser_dict = {\"1216\": 27, \"1721\": 67}\n",
    "\n",
    "for par in [\"nitrogen\", \"sulphur\"]:\n",
    "    for period, ser_id in ser_dict.items():\n",
    "        print(f\"Rasterising {par}, {period}...\")\n",
    "\n",
    "        # Get dep data\n",
    "        dep_gdf = cl.extract_deposition_as_gdf(\n",
    "            ser_id, par, eng, veg_class=\"grid average\"\n",
    "        ).to_crs(\"epsg:25833\")\n",
    "\n",
    "        # Save temporary file\n",
    "        temp = \"../raster/temp.geojson\"\n",
    "        dep_gdf.to_file(temp, driver=\"GeoJSON\")\n",
    "\n",
    "        # Convert to raster\n",
    "        col_name = f\"{par[0]}dep_meqpm2pyr\"\n",
    "        out_tif = (\n",
    "            f\"../raster/deposition/{par[0]}dep_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "        )\n",
    "        cl.vec_to_ras(temp, out_tif, snap_tif, col_name, -9999, \"Float32\")\n",
    "\n",
    "        # Delete temp file\n",
    "        os.remove(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Future EMEP scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_dep_totals(ds):\n",
    "    \"\"\"Takes an xarray netCDF dataset in the format used by EMEP and calculates\n",
    "    grid average deposition totals:\n",
    "\n",
    "        Total SOx = Wet SOx + Dry SOx\n",
    "        Total OxN = Wet OxN + Dry OxN\n",
    "        Total RedN = Wet RedN + Dry RedN\n",
    "        Total N = Total OxN + Total RedN\n",
    "\n",
    "    Args:\n",
    "        ds: xarray dataset\n",
    "\n",
    "    Returns:\n",
    "        New variables are added to 'ds'.\n",
    "    \"\"\"\n",
    "    # Pars of interest\n",
    "    par_list = [\n",
    "        \"DDEP_SOX_m2Grid\",\n",
    "        \"WDEP_SOX\",\n",
    "        \"DDEP_OXN_m2Grid\",\n",
    "        \"WDEP_OXN\",\n",
    "        \"DDEP_RDN_m2Grid\",\n",
    "        \"WDEP_RDN\",\n",
    "    ]\n",
    "\n",
    "    # Check N units are consistent\n",
    "    for par in par_list:\n",
    "        unit = ds[par].attrs[\"units\"]\n",
    "        assert unit in [\"mgS/m2\", \"mgN/m2\"], \"Units not consistent.\"\n",
    "\n",
    "    # Calculate total oxidised S\n",
    "    ds[\"DEP_SOX\"] = ds[\"WDEP_SOX\"] + ds[\"DDEP_SOX_m2Grid\"]\n",
    "    ds[\"DEP_SOX\"].attrs[\"units\"] = \"mgS/m2\"\n",
    "\n",
    "    # Calculate total oxidised N\n",
    "    ds[\"DEP_OXN\"] = ds[\"WDEP_OXN\"] + ds[\"DDEP_OXN_m2Grid\"]\n",
    "    ds[\"DEP_OXN\"].attrs[\"units\"] = \"mgN/m2\"\n",
    "\n",
    "    # Calculate total reduced N\n",
    "    ds[\"DEP_RDN\"] = ds[\"WDEP_RDN\"] + ds[\"DDEP_RDN_m2Grid\"]\n",
    "    ds[\"DEP_RDN\"].attrs[\"units\"] = \"mgN/m2\"\n",
    "\n",
    "    # Calculate total N\n",
    "    ds[\"DEP_TOTN\"] = (\n",
    "        ds[\"WDEP_OXN\"] + ds[\"WDEP_RDN\"] + ds[\"DDEP_OXN_m2Grid\"] + ds[\"DDEP_RDN_m2Grid\"]\n",
    "    )\n",
    "    ds[\"DEP_TOTN\"].attrs[\"units\"] = \"mgN/m2\"\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the scenario data and reproject to match the Høyanger snap grid\n",
    "scenario = \"Baseline\"  # 'Baseline', 'MFR' or 'Diet_low'\n",
    "snap_ds = rio.open_rasterio(snap_tif)\n",
    "ds_dict = {}\n",
    "for year in [2015, 2030, 2050]:\n",
    "    fpath = f\"/home/jovyan/shared/common/icp_waters/deposition_data/gp_review_scenarios/EMEP01_rv4.45_met2015_emis{year}_{scenario}_v1C_CCE-ICPwaters.nc\"\n",
    "    ds = rio.open_rasterio(fpath, mask_and_scale=True)\n",
    "    ds.rio.write_crs(4326, inplace=True)\n",
    "    ds = calculate_dep_totals(ds)\n",
    "    ds = ds.rio.reproject_match(snap_ds, resampling=Resampling.bilinear)\n",
    "    ds_dict[year] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030 DEP_TOTN 0.7238527536392212 0.7586063146591187\n",
      "2030 DEP_SOX 0.8607051372528076 0.9165170788764954\n",
      "2050 DEP_TOTN 0.62989741563797 0.6868270635604858\n",
      "2050 DEP_SOX 0.8461339473724365 0.9073213934898376\n"
     ]
    }
   ],
   "source": [
    "# Calculate change factors from EMEP as (future/2015_baseline), then apply\n",
    "# these factors to the NILU 2012-16 data to estimate future deposition\n",
    "nilu_series_name = \"1216\"\n",
    "base_ds = ds_dict[2015].copy()\n",
    "for year in [2030, 2050]:\n",
    "    fut_ds = ds_dict[year].copy()\n",
    "    for par in [\"DEP_TOTN\", \"DEP_SOX\"]:\n",
    "        fac_ds = fut_ds[par] / base_ds[par]\n",
    "\n",
    "        print(year, par, fac_ds.squeeze().min().values, fac_ds.squeeze().max().values)\n",
    "\n",
    "        if par.endswith(\"N\"):\n",
    "            nilu_path = f\"../raster/deposition/ndep_{nilu_series_name}_meqpm2pyr_{cell_size}m.tif\"\n",
    "            out_tif = f\"../raster/deposition/ndep_{year}bc_meqpm2pyr_{cell_size}m.tif\"\n",
    "        else:\n",
    "            nilu_path = f\"../raster/deposition/sdep_{nilu_series_name}_meqpm2pyr_{cell_size}m.tif\"\n",
    "            out_tif = f\"../raster/deposition/sdep_{year}bc_meqpm2pyr_{cell_size}m.tif\"\n",
    "\n",
    "        nilu_ds = rio.open_rasterio(nilu_path, mask_and_scale=True)\n",
    "        bias_cor_ds = nilu_ds.squeeze() * fac_ds.squeeze()\n",
    "        bias_cor_ds.rio.to_raster(out_tif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate exceedances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. SSWC\n",
    "\n",
    "**Note:** Values <0 are no longer set back to zero in the code below. See e-mail from Kari received 11.06.2020 at 15.08. Uncomment the line in the cell below to use the \"standard\" approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in [\"1216\", \"1721\", \"2030bc\", \"2050bc\"]:\n",
    "    # Read grids\n",
    "    s_tif = f\"../raster/deposition/sdep_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "    s_dep, s_ndv, epsg, extent = nivapy.spatial.read_raster(s_tif)\n",
    "\n",
    "    eno3_tif = f\"../raster/critical_loads/eno3_meqpm2pyr_{cell_size}m.tif\"\n",
    "    eno3fl, eno3_ndv, epsg, extent = nivapy.spatial.read_raster(eno3_tif)\n",
    "\n",
    "    claoaa_tif = f\"../raster/critical_loads/claoaa_meqpm2pyr_{cell_size}m.tif\"\n",
    "    claoaa, cla_ndv, epsg, extent = nivapy.spatial.read_raster(claoaa_tif)\n",
    "\n",
    "    # Set ndv\n",
    "    s_dep[s_dep == s_ndv] = np.nan\n",
    "    eno3fl[eno3fl == eno3_ndv] = np.nan\n",
    "    claoaa[claoaa == cla_ndv] = np.nan\n",
    "\n",
    "    # Set negative to zero\n",
    "    claoaa[claoaa < 0] = 0\n",
    "\n",
    "    # Exceedance\n",
    "    sswc_ex = s_dep + eno3fl - claoaa\n",
    "    del s_dep, eno3fl, claoaa\n",
    "\n",
    "    # Set <0 to 0\n",
    "    # sswc_ex[sswc_ex < 0] = 0\n",
    "\n",
    "    # Write geotif\n",
    "    sswc_tif = f\"../raster/exceedance/sswc_ex_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "    cl.write_geotiff(sswc_ex, sswc_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "    del sswc_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. FAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CL arrays\n",
    "for period in [\"1216\", \"1721\", \"2030bc\", \"2050bc\"]:\n",
    "    array_dict = {}\n",
    "\n",
    "    for name in [\"clminn\", \"clmaxnoaa\", \"clmins\", \"clmaxsoaa\"]:\n",
    "        # Read tif\n",
    "        tif_path = f\"../raster/critical_loads/{name}_meqpm2pyr_{cell_size}m.tif\"\n",
    "        data, ndv, epsg, extent = nivapy.spatial.read_raster(tif_path)\n",
    "        data[data == ndv] = np.nan\n",
    "        array_dict[name] = data\n",
    "\n",
    "    # Read dep arrays\n",
    "    for name in [\"ndep\", \"sdep\"]:\n",
    "        # Read tif\n",
    "        tif_path = f\"../raster/deposition/{name}_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "        data, ndv, epsg, extent = nivapy.spatial.read_raster(tif_path)\n",
    "        data[data == ndv] = np.nan\n",
    "        array_dict[name] = data\n",
    "\n",
    "    # Extract arrays from dict\n",
    "    cln_min = array_dict[\"clminn\"]\n",
    "    cln_max = array_dict[\"clmaxnoaa\"]\n",
    "    cls_min = array_dict[\"clmins\"]\n",
    "    cls_max = array_dict[\"clmaxsoaa\"]\n",
    "    dep_n = array_dict[f\"ndep\"]\n",
    "    dep_s = array_dict[f\"sdep\"]\n",
    "\n",
    "    # Estimate exceedances\n",
    "    ex_n, ex_s, reg_id = cl.vectorised_exceed_ns_icpm(\n",
    "        cln_min, cln_max, cls_min, cls_max, dep_n, dep_s\n",
    "    )\n",
    "\n",
    "    # Save GeoTiffs\n",
    "    # N\n",
    "    n_tif = f\"../raster/exceedance/fab_ex_n_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "    cl.write_geotiff(ex_n, n_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "    # S\n",
    "    s_tif = f\"../raster/exceedance/fab_ex_s_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "    cl.write_geotiff(ex_s, s_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "    # N+S\n",
    "    ns_tif = f\"../raster/exceedance/fab_ex_ns_{period}_meqpm2pyr_{cell_size}m.tif\"\n",
    "    cl.write_geotiff(ex_n + ex_s, ns_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "    # Exceedance 'region'\n",
    "    reg_tif = f\"../raster/exceedance/fab_ex_reg_id_{period}_{cell_size}m.tif\"\n",
    "    cl.write_geotiff(reg_id, reg_tif, snap_tif, -1, gdal.GDT_Float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/rasterstats/io.py:328: NodataWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>station_code</th>\n",
       "      <th>min_</th>\n",
       "      <th>mean_</th>\n",
       "      <th>max_</th>\n",
       "      <th>std_</th>\n",
       "      <th>count_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sswc_ex_1721_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>-38.080956</td>\n",
       "      <td>-37.833580</td>\n",
       "      <td>-36.833298</td>\n",
       "      <td>0.420881</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fab_ex_reg_id_2050bc_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>38772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fab_ex_n_1721_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fab_ex_reg_id_1721_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>38772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fab_ex_ns_2050bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fab_ex_s_1721_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fab_ex_n_2030bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sswc_ex_2030bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>-38.519913</td>\n",
       "      <td>-37.460735</td>\n",
       "      <td>-35.478287</td>\n",
       "      <td>0.962749</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fab_ex_s_2030bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fab_ex_n_2050bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fab_ex_s_2050bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fab_ex_reg_id_1216_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>38772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fab_ex_ns_1721_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fab_ex_ns_2030bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fab_ex_reg_id_2030bc_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.082016</td>\n",
       "      <td>38772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sswc_ex_1216_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>-37.457127</td>\n",
       "      <td>-36.465913</td>\n",
       "      <td>-34.462742</td>\n",
       "      <td>0.965629</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fab_ex_n_1216_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sswc_ex_2050bc_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>-38.635098</td>\n",
       "      <td>-37.568777</td>\n",
       "      <td>-35.590149</td>\n",
       "      <td>0.960272</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fab_ex_ns_1216_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fab_ex_s_1216_meqpm2pyr_50m</td>\n",
       "      <td>HOY</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset station_code       min_      mean_  \\\n",
       "0       sswc_ex_1721_meqpm2pyr_50m          HOY -38.080956 -37.833580   \n",
       "1         fab_ex_reg_id_2050bc_50m          HOY   0.000000   0.002244   \n",
       "2      fab_ex_n_1721_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "3           fab_ex_reg_id_1721_50m          HOY   0.000000   0.002244   \n",
       "4   fab_ex_ns_2050bc_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "5      fab_ex_s_1721_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "6    fab_ex_n_2030bc_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "7     sswc_ex_2030bc_meqpm2pyr_50m          HOY -38.519913 -37.460735   \n",
       "8    fab_ex_s_2030bc_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "9    fab_ex_n_2050bc_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "10   fab_ex_s_2050bc_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "11          fab_ex_reg_id_1216_50m          HOY   0.000000   0.002244   \n",
       "12    fab_ex_ns_1721_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "13  fab_ex_ns_2030bc_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "14        fab_ex_reg_id_2030bc_50m          HOY   0.000000   0.002244   \n",
       "15      sswc_ex_1216_meqpm2pyr_50m          HOY -37.457127 -36.465913   \n",
       "16     fab_ex_n_1216_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "17    sswc_ex_2050bc_meqpm2pyr_50m          HOY -38.635098 -37.568777   \n",
       "18    fab_ex_ns_1216_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "19     fab_ex_s_1216_meqpm2pyr_50m          HOY   0.000000   0.000000   \n",
       "\n",
       "         max_      std_  count_  \n",
       "0  -36.833298  0.420881   38743  \n",
       "1    3.000000  0.082016   38772  \n",
       "2    0.000000  0.000000   38743  \n",
       "3    3.000000  0.082016   38772  \n",
       "4    0.000000  0.000000   38743  \n",
       "5    0.000000  0.000000   38743  \n",
       "6    0.000000  0.000000   38743  \n",
       "7  -35.478287  0.962749   38743  \n",
       "8    0.000000  0.000000   38743  \n",
       "9    0.000000  0.000000   38743  \n",
       "10   0.000000  0.000000   38743  \n",
       "11   3.000000  0.082016   38772  \n",
       "12   0.000000  0.000000   38743  \n",
       "13   0.000000  0.000000   38743  \n",
       "14   3.000000  0.082016   38772  \n",
       "15 -34.462742  0.965629   38743  \n",
       "16   0.000000  0.000000   38743  \n",
       "17 -35.590149  0.960272   38743  \n",
       "18   0.000000  0.000000   38743  \n",
       "19   0.000000  0.000000   38743  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get paths to all dep and ex grids\n",
    "search_path1 = \"../raster/exceedance/*.tif\"\n",
    "flist1 = glob.glob(search_path1)\n",
    "search_path2 = \"../raster/deposition/*.tif\"\n",
    "flist2 = glob.glob(search_path2)\n",
    "search_path3 = \"../raster/critical_loads/*.tif\"\n",
    "flist3 = glob.glob(search_path3)\n",
    "flist = flist1 + flist2 + flist3\n",
    "\n",
    "df_list = []\n",
    "for fname in flist:\n",
    "    ds_name = os.path.split(fname)[1][:-4]\n",
    "    sum_df = nivapy.spatial.zonal_statistics(\n",
    "        cat_gdf[[\"station_id\", \"station_code\", \"geom\"]], fname, \"\"\n",
    "    )\n",
    "    sum_df[\"dataset\"] = ds_name\n",
    "    df_list.append(sum_df)\n",
    "\n",
    "sum_df = pd.concat(df_list, sort=True)\n",
    "sum_df = sum_df[\n",
    "    [\"dataset\", \"station_code\", \"min_\", \"mean_\", \"max_\", \"std_\", \"count_\"]\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Save\n",
    "csv_path = f\"../output/hoyanger_results_summary_meqpm2pyr_{catch_set}_catches.csv\"\n",
    "sum_df.to_csv(csv_path, index=False)\n",
    "\n",
    "sum_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
