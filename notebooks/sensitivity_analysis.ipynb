{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import critical_loads as cl\n",
    "import gdal\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostGIS\n",
    "eng = nivapy.da.connect_postgis(database=\"critical_loads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical loads for water: sensitivity analysis\n",
    "\n",
    "This notebook explores the sensitivity of the exceedance calculations (SSWC and FAB) to changes in the input critical loads parameters. See e-mail from Kari received 17.11.2020 at 10.01 for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User input\n",
    "\n",
    "Choose the deposition dataset and resolution you wish to work with (see notebook 01 for a list of available `series_ids`) and set the parameter combinations to explore. For everything here, we will use \"standard\" `BC0` and deposition data from 2012 to 2016 (new grid), which is series ID 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_id = 28\n",
    "short_name = \"1216\"\n",
    "cell_size = 120\n",
    "bc0 = \"BC0\"\n",
    "base_fold = f\"/home/jovyan/shared/critical_loads/raster/sensitivity_analysis\"\n",
    "\n",
    "# Values to try for each parameter\n",
    "param_dict = {\n",
    "    \"Runoff\": [1, 1.03, 1.05],\n",
    "    \"Ni\": [3.57, 7.14, 14.23],\n",
    "    \"NO3N\": [1, 0.5, 0.1],\n",
    "    \"Fde\": [0.1, 0.2, 0.5],\n",
    "}\n",
    "\n",
    "# Whether values in 'param_dict' are absolute parameter values ('abs') or multiplication factors\n",
    "# to apply to existing parameters ('fac')\n",
    "param_type = {\n",
    "    \"Runoff\": \"fac\",\n",
    "    \"Ni\": \"abs\",\n",
    "    \"NO3N\": \"fac\",\n",
    "    \"Fde\": \"abs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loop over parameter combinations\n",
    "\n",
    "The code below loops over all the parameter combinations defined above. It's messy/hacky as it's mostly copy-pasted from other notebooks, but should work OK.\n",
    "\n",
    "If we save all the critical loads grids, **each run generates around 240 MB of data and takes about 1 minute 20 seconds. Care is therefore needed if performaing a large number of runs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You have chosen 81 parameter combinations.\n",
      "         The code below will generate ~19.44 GB of data and will take around 1.80 hours to complete.\n"
     ]
    }
   ],
   "source": [
    "# Generate param combos\n",
    "param_grid = ParameterGrid(param_dict)\n",
    "\n",
    "print(f\"WARNING: You have chosen {len(param_grid)} parameter combinations.\")\n",
    "print(f\"         The code below will generate ~{len(param_grid)*0.240:.2f} GB of data \"\n",
    "      f\"and will take around {len(param_grid)*1.33/60:.2f} hours to complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################################\n",
      "Processing run 001\n",
      "\n",
      "Rasterising claoaa_meqpm2pyr...\n",
      "Rasterising eno3_flux_meqpm2pyr...\n",
      "Rasterising clminn_meqpm2pyr...\n",
      "Rasterising clmaxnoaa_meqpm2pyr...\n",
      "Rasterising clmaxsoaa_meqpm2pyr...\n",
      "Rasterising anclimit_ueqpl...\n",
      "Rasterising anclimitoaa_ueqpl...\n",
      "Rasterising bc0_ueqpl...\n",
      "Rasterising clmins_meqpm2pyr...\n",
      "Rasters saved to:\n",
      "    /home/jovyan/shared/critical_loads/raster/sensitivity_analysis/run_001/water\n",
      "Exceedance grid saved to:\n",
      "    /home/jovyan/shared/critical_loads/raster/sensitivity_analysis/run_001/exceedance/sswc_ex_meqpm2pyr_1216_120m.tif\n",
      "########################################################################################\n",
      "Processing run 002\n",
      "\n",
      "Rasterising claoaa_meqpm2pyr...\n",
      "Rasterising eno3_flux_meqpm2pyr...\n",
      "Rasterising clminn_meqpm2pyr...\n",
      "Rasterising clmaxnoaa_meqpm2pyr...\n"
     ]
    }
   ],
   "source": [
    "# Loop over combos\n",
    "df_list = []\n",
    "for idx, params in enumerate(param_grid):\n",
    "    run_id = idx + 1\n",
    "    print(\n",
    "        \"########################################################################################\"\n",
    "    )\n",
    "    print(f\"Processing run {run_id:03d}\\n\")\n",
    "    # Read required data from db\n",
    "    par_df = pd.read_sql(\n",
    "        \"SELECT id as parameter_id, name, class FROM water.parameter_definitions\",\n",
    "        eng,\n",
    "    )\n",
    "    df = pd.read_sql(\"SELECT * FROM water.blr_required_parameters\", eng)\n",
    "\n",
    "    # Restructure\n",
    "    df = pd.merge(df, par_df, how=\"left\", on=\"parameter_id\")\n",
    "    del df[\"parameter_id\"], df[\"class\"]\n",
    "    df = df.pivot(index=\"region_id\", columns=\"name\", values=\"value\")\n",
    "    df.index.name = \"Region_id\"\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns.name = \"\"\n",
    "\n",
    "    # Add optional pars with default values\n",
    "    default_vals = {\n",
    "        \"Catch_area\": 1,\n",
    "        \"Lake_area\": 0.05,\n",
    "        \"Forest_area\": 0.95,\n",
    "        \"Ni\": 3.57,\n",
    "        \"Fde\": 0.1,\n",
    "        \"SN\": 5,\n",
    "        \"SS\": 0.5,\n",
    "    }\n",
    "    for key in default_vals.keys():\n",
    "        df[key] = default_vals[key]\n",
    "\n",
    "    # Update params\n",
    "    for key in params.keys():\n",
    "        if param_type[key] == \"fac\":\n",
    "            # Apply change factor\n",
    "            df[key] = df[key] * params[key]\n",
    "        elif param_type[key] == \"abs\":\n",
    "            # Set value explicitly\n",
    "            df[key] = params[key]\n",
    "        else:\n",
    "            raise ValueError(\"Parameter type not recognised (must be 'fac' or 'abs').\")\n",
    "\n",
    "    # Split into required and optional params\n",
    "    req_df = df[\n",
    "        [\n",
    "            \"Region_id\",\n",
    "            \"Ca\",\n",
    "            \"Cl\",\n",
    "            \"K\",\n",
    "            \"Mg\",\n",
    "            \"NO3N\",\n",
    "            \"Na\",\n",
    "            \"Nupt\",\n",
    "            \"Runoff\",\n",
    "            \"SO4\",\n",
    "            \"TOC\",\n",
    "        ]\n",
    "    ].copy()\n",
    "    opt_df = df[\n",
    "        [\"Region_id\", \"Catch_area\", \"Lake_area\", \"Forest_area\", \"Ni\", \"Fde\", \"SN\", \"SS\"]\n",
    "    ].copy()\n",
    "\n",
    "    # Rasterise critical loads for water\n",
    "    cl_fold = os.path.join(base_fold, f\"run_{run_id:03d}/water\")\n",
    "    if not os.path.exists(cl_fold):\n",
    "        os.makedirs(cl_fold)\n",
    "    cl.rasterise_water_critical_loads(\n",
    "        eng,\n",
    "        cl_fold,\n",
    "        cell_size,\n",
    "        bc0=bc0,\n",
    "        req_df=req_df,\n",
    "        opt_df=opt_df,\n",
    "        mag_df=None,\n",
    "        df_to_csv=True,\n",
    "    )\n",
    "\n",
    "    # SSWC\n",
    "    ex_fold = os.path.join(base_fold, f\"run_{run_id:03d}/exceedance\")\n",
    "    if not os.path.exists(ex_fold):\n",
    "        os.makedirs(ex_fold)\n",
    "    sswc_df = cl.calculate_water_exceedance_sswc(\n",
    "        ser_id,\n",
    "        short_name,\n",
    "        cl_fold,\n",
    "        ex_fold,\n",
    "        cell_size=cell_size,\n",
    "        bc0=bc0,\n",
    "        neg_to_zero=True,\n",
    "    )\n",
    "\n",
    "    sswc_path = os.path.join(\n",
    "        ex_fold, f\"sswc_ex_meqpm2pyr_{short_name}_{cell_size}m.tif\"\n",
    "    )\n",
    "    sswc_ex, ndv, epsg, extent = nivapy.spatial.read_raster(sswc_path)\n",
    "    sswc_ex = sswc_ex.astype(np.float32)\n",
    "    sswc_ex[sswc_ex == ndv] = np.nan\n",
    "\n",
    "    # FAB\n",
    "    # Read CL arrays\n",
    "    array_dict = {}\n",
    "    for par in [\n",
    "        \"clminn_meqpm2pyr\",\n",
    "        \"clmins_meqpm2pyr\",\n",
    "        \"clmaxnoaa_meqpm2pyr\",\n",
    "        \"clmaxsoaa_meqpm2pyr\",\n",
    "    ]:\n",
    "        # Read tif\n",
    "        tif_path = os.path.join(cl_fold, f\"{par}_{cell_size}m.tif\")\n",
    "        data, ndv, epsg, extent = nivapy.spatial.read_raster(tif_path)\n",
    "\n",
    "        # Set NDV\n",
    "        data[data == ndv] = np.nan\n",
    "\n",
    "        # Add to dict\n",
    "        array_dict[par] = data\n",
    "\n",
    "    # Read dep arrays\n",
    "    dep_path = r\"/home/jovyan/shared/critical_loads/raster/deposition\"\n",
    "    for par in [\"ndep_mgpm2pyr\", \"sdep_mgpm2pyr\"]:\n",
    "        # Read tif\n",
    "        tif_path = os.path.join(dep_path, f\"{par}_{short_name}_{cell_size}m.tif\")\n",
    "        data, ndv, epsg, extent = nivapy.spatial.read_raster(tif_path)\n",
    "        data = data.astype(np.float32)\n",
    "\n",
    "        # Set NDV\n",
    "        data[data == ndv] = np.nan\n",
    "\n",
    "        # Add to dict\n",
    "        array_dict[par] = data\n",
    "\n",
    "    # Extract arrays from dict\n",
    "    cln_min = array_dict[\"clminn_meqpm2pyr\"]\n",
    "    cln_max = array_dict[\"clmaxnoaa_meqpm2pyr\"]\n",
    "    cls_min = array_dict[\"clmins_meqpm2pyr\"]\n",
    "    cls_max = array_dict[\"clmaxsoaa_meqpm2pyr\"]\n",
    "    dep_n = array_dict[\"ndep_mgpm2pyr\"] / 14  # Convert to meq\n",
    "    dep_s = array_dict[\"sdep_mgpm2pyr\"] * 2 / 32.06  # Convert to meq\n",
    "\n",
    "    # Estimate exceedances\n",
    "    ex_n, ex_s, reg_id = cl.vectorised_exceed_ns_icpm(\n",
    "        cln_min, cln_max, cls_min, cls_max, dep_n, dep_s\n",
    "    )\n",
    "\n",
    "    # Get exceeded area\n",
    "    ex = ex_n + ex_s\n",
    "    fab_ex_area = np.count_nonzero(ex > 0) * cell_size * cell_size / 1.0e6\n",
    "    nor_area = np.count_nonzero(~np.isnan(dep_s)) * cell_size * cell_size / 1.0e6\n",
    "    fab_ex_pct = 100 * fab_ex_area / nor_area\n",
    "\n",
    "    # Build df and tidy\n",
    "    fab_ex_df = pd.DataFrame(\n",
    "        {\n",
    "            \"exceeded_area_km2\": fab_ex_area,\n",
    "            \"total_area_km2\": nor_area,\n",
    "            \"exceeded_area_pct\": fab_ex_pct,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    fab_ex_df = fab_ex_df.round(0).astype(int)\n",
    "    fab_ex_df[\"series_id\"] = ser_id\n",
    "    fab_ex_df[\"medium\"] = \"water_fab\"\n",
    "\n",
    "    fab_ex_df = fab_ex_df[\n",
    "        [\n",
    "            \"series_id\",\n",
    "            \"medium\",\n",
    "            \"total_area_km2\",\n",
    "            \"exceeded_area_km2\",\n",
    "            \"exceeded_area_pct\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Save rasters\n",
    "    snap_tif = (\n",
    "        f\"/home/jovyan/shared/critical_loads/raster/blr_land_mask_{cell_size}m.tif\"\n",
    "    )\n",
    "\n",
    "#     n_tif = os.path.join(ex_fold, f\"fab_exn_meqpm2pyr_{short_name}_{cell_size}m.tif\")\n",
    "#     cl.write_geotiff(ex_n, n_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "#     s_tif = os.path.join(ex_fold, f\"fab_exs_meqpm2pyr_{short_name}_{cell_size}m.tif\")\n",
    "#     cl.write_geotiff(ex_s, s_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "    ns_tif = os.path.join(ex_fold, f\"fab_exns_meqpm2pyr_{short_name}_{cell_size}m.tif\")\n",
    "    cl.write_geotiff(ex_n + ex_s, ns_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "#     reg_tif = os.path.join(ex_fold, f\"fab_ex_reg_id_{short_name}_{cell_size}m.tif\")\n",
    "#     cl.write_geotiff(reg_id, reg_tif, snap_tif, -1, gdal.GDT_Float32)\n",
    "\n",
    "    # Assign run ID to params\n",
    "    params[\"run_id\"] = run_id\n",
    "\n",
    "    params[\"norway_area_km2\"] = nor_area\n",
    "    \n",
    "    # Add exceedance stats\n",
    "    sswc_ex_area = sswc_df.loc[0, \"exceeded_area_km2\"]\n",
    "    params[\"sswc_ex_area_km2\"] = sswc_ex_area\n",
    "\n",
    "    sswc_ex_pct = sswc_df.loc[0, \"exceeded_area_pct\"]\n",
    "    params[\"sswc_ex_area_pct\"] = sswc_ex_pct\n",
    "\n",
    "    assert np.nanmin(sswc_ex) == 0\n",
    "    params[\"sum_sswc_ex_Meqpyr\"] = np.nansum(sswc_ex) * 120 * 120 / 1e9\n",
    "\n",
    "    params[\"fab_ex_area_km2\"] = fab_ex_area\n",
    "\n",
    "    params[\"fab_ex_area_pct\"] = fab_ex_pct\n",
    "\n",
    "    assert np.nanmin(ex) == 0\n",
    "    params[\"sum_fab_ex_Meqpyr\"] = np.nansum(ex) * 120 * 120 / 1e9\n",
    "\n",
    "    # Build summary output\n",
    "    df_list.append(pd.DataFrame(params, index=[0]))\n",
    "\n",
    "\n",
    "# Build dataframe of run details\n",
    "res_df = pd.concat(df_list, axis=\"rows\").reset_index(drop=True)\n",
    "par_cols = list(res_df.columns)\n",
    "par_cols.remove(\"run_id\")\n",
    "res_df = res_df[[\"run_id\"] + par_cols]\n",
    "\n",
    "csv_path = os.path.join(base_fold, \"sensitivity_analysis_summary.csv\")\n",
    "res_df.to_csv(csv_path, index=False)\n",
    "res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
