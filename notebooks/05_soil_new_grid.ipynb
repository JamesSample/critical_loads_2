{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nivapy3 as nivapy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdal\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import critical_loads as cl\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostGIS\n",
    "eng = nivapy.da.connect_postgis(database='critical_loads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical loads: Soil workflow (high-resolution method; 2018 onwards)\n",
    "\n",
    "In Spring 2018, the worflow for calculating critical loads was refined to make use of new, higher-resolution input datasets. During November 2018, data handling for the Critical Loads project was also redesigned, with the ultimate aim of centralising all key datasets on NIVA's new cloud platform. \n",
    "\n",
    "This notebook deals with data processing for the soil exceedance calculations, using the new 0.1 degree deposition grid and the \"old\" soil CLs. Exceedances are calculated as \n",
    "\n",
    "$$E_{soil} = S_{dep} âˆ’ CL_{soil}$$\n",
    "\n",
    "(See e-mail from Kari received 01/11/2017 at 13.47 for details).\n",
    "\n",
    "**Note:** Deposition data supplied prior to 2017-18 use a different spatial grid (the \"BLR\" grid). **The workflow here only applies to data supplied from 2017-18 onwards**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Organising soil data on the DSToolkit\n",
    "\n",
    "NIVA's JupyterHub includes a PostGIS database server capable of storing relational and vector geospatial datasets. I have created a database named `critical_loads` and, within this, a schema named `soil`. This schema contains the following table:\n",
    "\n",
    " * **s_critical_load:** Non-spatial table specifying the soil critical load for around 660 BLR cells with \"productive forest\" (see e-mail from Kari received 16.11.2017 at 12.52 for details). This dataset was originally exported from `RESA2.TALEGREN_VALUES`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define data series and resolution of interest\n",
    "\n",
    "Choose the dataset you whish to work with (see notebook 01 for a list of available `series_ids`.\n",
    "\n",
    "**Note:** If you want to work with the 30 m resolution data, you will need to **log-in on one of the high memory machines**, as the grids involved are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series of interest\n",
    "ser_id = 28\n",
    "\n",
    "# Choose cell size (30m or 60m)\n",
    "cell_size = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create raster of soil critical loads\n",
    "\n",
    "The code below does not need to be re-run unless the soil critical loads are updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snap raster\n",
    "snap_tif = f'/home/jovyan/shared/critical_loads/raster/sat_veg_{cell_size}m_cr_lds_div100.tif'\n",
    "\n",
    "# Soil CL raster to create\n",
    "cl_tif = f'/home/jovyan/shared/critical_loads/raster/soil_cl_{cell_size}m.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all CLs for S\n",
    "#sql = (\"SELECT * FROM soil.s_critical_load\")\n",
    "#cl_df = pd.read_sql(sql, eng)\n",
    "#\n",
    "## Read BLR grid\n",
    "#gdf = nivapy.da.read_postgis('deposition', 'dep_grid_blr', eng)\n",
    "#\n",
    "## Join\n",
    "#gdf = gdf.merge(cl_df, on='blr')\n",
    "#\n",
    "## Rasterise\n",
    "#gdf.to_file('temp_soil_cl.geojson', driver='GeoJSON')\n",
    "#cl.vec_to_ras('temp_soil_cl.geojson', cl_tif, snap_tif, 'cl_mgSpm2', -1, 'Int16')\n",
    "#os.remove('temp_soil_cl.geojson') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate exceedances for soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster of S deposition (created in notebook 01)\n",
    "sdep_tif = f'/home/jovyan/shared/critical_loads/raster/deposition/sdep_12-16_{cell_size}m.tif'\n",
    "\n",
    "# Exceedance .tif to create\n",
    "ex_tif = f'/home/jovyan/shared/critical_loads/raster/exceedance/soil_ex_12-16_{cell_size}m.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>total_area_km2</th>\n",
       "      <th>exceeded_area_km2</th>\n",
       "      <th>exceeded_area_pct</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>108681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>soil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  total_area_km2  exceeded_area_km2  exceeded_area_pct medium\n",
       "0         28          108681                  0                  0   soil"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read tifs\n",
    "dep_s, ndv, epsg, extent = nivapy.spatial.read_raster(sdep_tif)\n",
    "dep_s = dep_s.astype(np.float32)\n",
    "dep_s[dep_s==ndv] = np.nan\n",
    "\n",
    "cl_soil, ndv, epsg, extent = nivapy.spatial.read_raster(cl_tif)\n",
    "cl_soil = cl_soil.astype(np.float32)\n",
    "cl_soil[cl_soil==ndv] = np.nan\n",
    "\n",
    "# Exceedance\n",
    "ex_soil = dep_s - cl_soil\n",
    "ex_soil[ex_soil<0] = 0\n",
    "\n",
    "# Get exceeded area\n",
    "ex_area = np.count_nonzero(ex_soil > 0)*cell_size*cell_size/1.E6\n",
    "nor_area = np.count_nonzero(~np.isnan(ex_soil))*cell_size*cell_size/1.E6\n",
    "ex_pct = 100*ex_area/nor_area\n",
    "\n",
    "ex_df = pd.DataFrame({'series_id':ser_id,\n",
    "                      'total_area_km2':nor_area,\n",
    "                      'exceeded_area_km2':ex_area,\n",
    "                      'exceeded_area_pct':ex_pct},\n",
    "                     index=[0])\n",
    "ex_df = ex_df.round(0).astype(int)\n",
    "ex_df['medium'] = 'soil'\n",
    "ex_df = ex_df[['series_id', 'medium', 'total_area_km2', 'exceeded_area_km2', \n",
    "               'exceeded_area_pct']]\n",
    "\n",
    "# Set NaN to -1\n",
    "ex_soil[np.isnan(ex_soil)] = -1\n",
    "\n",
    "# Save geotiff\n",
    "cl.write_geotiff(ex_soil, ex_tif, snap_tif, -1, gdal.GDT_Int16)\n",
    "\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you connected to the database with `admin=True`**, these results can be saved back to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write summary data to db\n",
    "#ex_df.to_sql('national_summary', \n",
    "#             eng,\n",
    "#             'summaries',\n",
    "#             if_exists='append',\n",
    "#             index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
